import os
import glob
import re
import gzip
import json
import subprocess

def read_file(filepath, binary = False):
    if binary:
        output_handle = open(filepath, 'rb')
    elif filepath.endswith('.gz'):
        output_handle = gzip.open(filepath, 'r')
    else:
        output_handle = open(filepath, 'r')
    contents = output_handle.read()
    output_handle.close()
    return contents


def write_file(filepath, contents, ftype = 'w'):
    output_handle = open(filepath, ftype)
    output_handle.write(contents)
    output_handle.close()


def Popen(outdir, args):
    subp = subprocess.Popen([str(arg) for arg in args], stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=outdir, env={'SPARKSXDIR' : '/netapp/home/klabqb3backrub/tools/sparks-x'})
    output = subp.communicate()
    return output[0], output[1], subp.returncode # 0 is stdout, 1 is stderr

def is_valid_fragment(original_residue_id, mapping, nmerage):
    '''A function which determines whether a residue ID (original_residue_id) should be included in the nmer files generated by the mapping.'''
    for r in mapping['segment_list']:
        r = sorted(r)
        if r[0] - nmerage + 1 <= original_residue_id <= r[1] + nmerage - 1:
            return True
    return False

def rewrite_score_file(task_dir, old_filepath, backup_filepath, new_filepath, mapping, nmerage, num_fragments):
    lines = read_file(old_filepath).split('\n')

    reverse_mapping = mapping['reverse_mapping'].get(task_dir) or mapping['reverse_mapping']['FASTA']
    must_zip_output = old_filepath.endswith('.gz')
    new_lines = []
    for l in lines:
        if l.startswith('#') or not(l.strip()):
            new_lines.append(l)
        else:
            tokens = l.split()
            assert(len(tokens) == 14)
            assert(l[:11].strip().isdigit())
            assert(l[11] == ' ')
            residue_id = int(l[:11])
            original_residue_id = reverse_mapping.get(str(residue_id))
            assert(original_residue_id != None)
            # Prune records which are not needed for these nmers
            if is_valid_fragment(original_residue_id, mapping, nmerage):
                new_lines.append('%s%s' % (str(reverse_mapping[str(residue_id)]).rjust(11), l[11:]))
                assert(len(new_lines[-1]) == len(l))

    print('Rewriting fragments score file %s for %d-mers with %d fragments...' % (old_filepath, nmerage, num_fragments))
    os.rename(old_filepath, backup_filepath)
    write_file(new_filepath, '\n'.join(new_lines))
    if os.path.exists(new_filepath + '.gz'):
        os.remove(new_filepath + '.gz')
    if must_zip_output:
        stdout, stderr, errorcode = Popen(os.path.split(new_filepath)[0], ['gzip', os.path.split(new_filepath)[1]])
        assert(errorcode == 0)

def rewrite_fragments_file(task_dir, old_filepath, backup_filepath, new_filepath, mapping, nmerage, num_fragments):
    lines = read_file(old_filepath).split('\n')

    reverse_mapping = mapping['reverse_mapping'].get(task_dir) or mapping['reverse_mapping']['FASTA']
    must_zip_output = old_filepath.endswith('.gz')

    # Rewrite the position: lines i.e. renumber the fragments in the file
    new_lines = []
    for l in lines:
        if l.startswith('position:'):
            assert(l.find('neighbors:') != -1)
            assert(l.find('neighbors:') != -1)
            tokens = l.split()
            assert(len(tokens) == 4)
            assert(l[9:22].strip().isdigit())
            assert(l[22] == ' ')
            residue_id = int(l[9:22])
            assert(reverse_mapping.get(str(residue_id)))
            new_lines.append('position:%s%s' % (str(reverse_mapping[str(residue_id)]).rjust(13), l[22:]))
            assert(len(new_lines[-1]) == len(l))
        else:
            new_lines.append(l)

    # Prune records which are not needed for these nmers
    new_content = '%s_grog_' % '\n'.join(new_lines)
    fragment_score_blocks = re.findall('(position:.*?)(?=position:|_grog_)', new_content, re.DOTALL)
    new_blocks = []
    for b in fragment_score_blocks:
        assert(b.startswith('position:'))
        residue_id = int(b.split('\n')[0][9:].split()[0])
        if is_valid_fragment(residue_id, mapping, nmerage):
            new_blocks.append(b)
    new_blocks = ''.join(new_blocks)

    print('Rewriting fragments file %s for %d-mers with %d fragments...' % (old_filepath, nmerage, num_fragments))
    os.rename(old_filepath, backup_filepath)
    write_file(new_filepath, new_blocks)
    if os.path.exists(new_filepath + '.gz'):
        os.remove(new_filepath + '.gz')
    if must_zip_output:
        stdout, stderr, errorcode = Popen(os.path.split(new_filepath)[0], ['gzip', os.path.split(new_filepath)[1]])
        assert(errorcode == 0)

def filter_fragments_file_by_secondary_structure(fragments_filepath, new_filepath, mapping, nmerage):

    stats = []
    must_zip_output = fragments_filepath.endswith('.gz')

    all_fragments = read_file(fragments_filepath) + '_grog_'
    fragment_score_blocks = re.findall('(position:.*?)(?=position:|_grog_)', all_fragments, re.DOTALL)
    new_blocks = []
    for b in fragment_score_blocks:
        # Iterate over the set of positions
        assert(b.startswith('position:'))
        header_line =  b.split('\n')[0]
        header_tokens = header_line.split()
        start_residue_id = int(header_tokens[1])
        num_fragments = int(header_tokens[3])

        new_block = []
        position_fragments = [pf for pf in b.split('\n\n') if pf.strip()]
        assert(len(position_fragments) == num_fragments + 1)
        assert(position_fragments[0].find('position:') != -1)

        for pf in position_fragments[1:]:
            # Iterate over the set of fragments per position
            passed_filter = True
            pflines = [l for l in pf.split('\n') if l.strip()]
            assert(len(pflines) == nmerage)
            c = start_residue_id
            for pfline in pflines:
                if str(c) in mapping:
                    expected_secondary_structure = mapping[str(c)]
                    fragment_secondary_structure = pfline.strip().split()[4]
                    if fragment_secondary_structure not in expected_secondary_structure:
                        passed_filter = False
                c += 1
            if passed_filter:
                new_block.append(pf)

        new_num_neighbors = len(new_block)
        if new_num_neighbors == 0:
            sys.stderr.write('WARNING: The block starting at position %d has no fragments remaining aftering filtering by secondary structure.\n' % start_residue_id)

        # Add the header by default
        mtchs = re.match('^(position:\s+\d+\s+neighbors:)(\s+\d+)(\s)*$', header_line)
        assert(mtchs)
        new_header_line = '%s%s%s' % (mtchs.group(1), str(new_num_neighbors).rjust(len(mtchs.group(2))), mtchs.group(3) or '')
        new_block.insert(0, new_header_line)
        new_blocks.append('\n\n'.join(new_block))
        stats.append(map(str, (start_residue_id, num_fragments, new_num_neighbors)))
    new_blocks = '\n\n'.join(new_blocks)

    s = 'Secondary structure filtering summary (%dmers)' % nmerage
    print('\n%s\n%s' % (s, len(s) * '*'))
    print('Residue ID     Number of fragments      Number of fragments after filtering')
    for stat in stats:
        print('%s%s%s' % (stat[0].ljust(15), stat[1].ljust(25), stat[2].ljust(0)))

    print('\nRewriting fragments file %s as %s for %d-mers with %d fragments...\n' % (fragments_filepath, new_filepath, nmerage, num_fragments))
    write_file(new_filepath, new_blocks)
    if os.path.exists(new_filepath + '.gz'):
        os.remove(new_filepath + '.gz')
    if must_zip_output:
        stdout, stderr, errorcode = Popen(os.path.split(new_filepath)[0], ['gzip', os.path.split(new_filepath)[1]])
        assert(errorcode == 0)

def post_process(task_dir):

    if os.path.exists('segment_map.json'):
        mapping = json.loads(open('segment_map.json').read())
        for f in sorted(glob.glob(os.path.join(task_dir, "*mers")) + glob.glob(os.path.join(task_dir, "*mers.gz"))):
            if f.find('backup') != -1 or f.find('rewrite') != -1:
                continue
            mtchs = re.match('(.*?frags)[.](\d+)[.]score[.](\d+)[.](\d+)mers[.]?(gz)?', f)
            if mtchs:
                assert(mtchs.group(2) == mtchs.group(4))
                nmerage = int(mtchs.group(2))
                num_fragments = int(mtchs.group(3))
                old_filepath = mtchs.group(0)
                # Kale wanted to change the filename for the scores so that it is easier to distinguish between score and fragments files using glob

                backup_filepath = '%s.%s.%smers.backup.score.%s' % (mtchs.group(1), mtchs.group(3), mtchs.group(4), mtchs.group(5))
                new_filepath = ('%s.%s.%smers.rewrite.score.%s' % (mtchs.group(1), mtchs.group(3), mtchs.group(4), mtchs.group(5))).replace('.gz', '')
                rewrite_score_file(task_dir, old_filepath, backup_filepath, new_filepath, mapping, nmerage, num_fragments)
            else:
                mtchs = re.match('(.*)[.](\d+)[.](\d+)mers[.]?(gz)?', f)
                if mtchs:
                    nmerage = int(mtchs.group(3))
                    num_fragments = int(mtchs.group(2))
                    old_filepath = mtchs.group(0)
                    backup_filepath= '%s.%s.%smers.backup.%s' % (mtchs.group(1), mtchs.group(2), mtchs.group(3), mtchs.group(4))
                    new_filepath= ('%s.%s.%smers.rewrite.%s' % (mtchs.group(1), mtchs.group(2), mtchs.group(3), mtchs.group(4))).replace('.gz', '')
                    rewrite_fragments_file(task_dir, old_filepath, backup_filepath, new_filepath, mapping, nmerage, num_fragments)

    if os.path.exists('ss_filter.json'):
        mapping = json.loads(open('ss_filter.json').read())['secondary_structure_filter']
        for f in sorted(glob.glob(os.path.join(task_dir, "*mers.rewrite")) + glob.glob(os.path.join(task_dir, "*mers.rewrite.gz"))):
            if f.find('rewrite') != -1:
                mtchs = re.match('(.*)[.](\d+)[.](\d+)mers[.]?(gz)?', f)
                assert(mtchs)
                nmerage = int(mtchs.group(3))

                mtchs = re.match('(.*?).rewrite(.*)', f)
                new_filepath = ('%s.ssfilter%s' % (mtchs.group(1), mtchs.group(2))).replace('.gz', '')

                filter_fragments_file_by_secondary_structure(f, new_filepath, mapping, nmerage)

